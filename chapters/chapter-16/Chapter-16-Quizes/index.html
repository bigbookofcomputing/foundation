
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A comprehensive guide to the foundations of computational science">
      
      
        <meta name="author" content="Big Book of Computing">
      
      
        <link rel="canonical" href="https://bigbookofcomputing.github.io/chapters/chapter-16/Chapter-16-Quizes/">
      
      
      
      
        
      
      
      <link rel="icon" href="../../../assets/book-icon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Chapter 16 Quizes - Big Book of Computing | Foundation of Computational Science</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    
      <link rel="stylesheet" href="../../../static/styles.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-ECS7B3X8JM"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-ECS7B3X8JM",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-ECS7B3X8JM",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>if("undefined"!=typeof __md_analytics){var consent=__md_get("__consent");consent&&consent.analytics&&__md_analytics()}</script>
  

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Big Book of Computing | Foundation of Computational Science" class="md-header__button md-logo" aria-label="Big Book of Computing | Foundation of Computational Science" data-md-component="logo">
      
  <img src="../../../assets/book-icon.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Big Book of Computing | Foundation of Computational Science
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Chapter 16 Quizes
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5M7 15a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/bigbookofcomputing/foundation" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../contents/" class="md-tabs__link">
        
  
  
    
  
  Contents

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../introduction/" class="md-tabs__link">
        
  
  
    
  
  Introduction

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter-1/Chapter-1-Essay/" class="md-tabs__link">
          
  
  
    
  
  Chapters

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter-1/Chapter-1-WorkBook/" class="md-tabs__link">
          
  
  
    
  
  WorkBooks

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter-1/Chapter-1-CodeBook/" class="md-tabs__link">
          
  
  
    
  
  CodeBooks

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Big Book of Computing | Foundation of Computational Science" class="md-nav__button md-logo" aria-label="Big Book of Computing | Foundation of Computational Science" data-md-component="logo">
      
  <img src="../../../assets/book-icon.png" alt="logo">

    </a>
    Big Book of Computing | Foundation of Computational Science
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/bigbookofcomputing/foundation" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contents/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Contents
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Introduction
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Chapters
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Chapters
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-1/Chapter-1-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1. Digital Lab Notebook
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-2/Chapter-2-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2. Computational Numbers
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-3/Chapter-3-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    3. Root Finding
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-4/Chapter-4-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    4. Interpolation & Fitting
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-5/Chapter-5-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    5. Numerical Differentiation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-6/Chapter-6-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    6. Numerical Integration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-7/Chapter-7-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    7. Initial Value Problems I
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-8/Chapter-8-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    8. Initial Value Problems II
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-9/Chapter-9-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    9. Boundary Value Problems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-10/Chapter-10-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    10. Elliptic PDEs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-11/Chapter-11-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    11. Parabolic PDEs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-12/Chapter-12-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    12. Hyperbolic PDEs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-13/Chapter-13-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    13. Systems of Linear Equations
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-14/Chapter-14-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    14. Eigenvalue Problems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-15/Chapter-15-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    15. Fourier Analysis & The FFT
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter-16-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    16. Data-Driven Analysis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-17/Chapter-17-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    17. Randomness in Physics
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    WorkBooks
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    WorkBooks
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-1/Chapter-1-WorkBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1. Digital Lab Notebook
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-2/Chapter-2-WorkBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2. Computational Numbers
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-3/Chapter-3-WorkBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    3. Root Finding
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-4/Chapter-4-WorkBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    4. Interpolation & Fitting
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-5/Chapter-5-WorkBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    5. Numerical Differentiation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-6/Chapter-6-WorkBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    6. Numerical Integration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-7/Chapter-7-WorkBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    7. Initial Value Problems I
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-8/Chapter-8-WorkBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    8. Initial Value Problems II
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-9/Chapter-9-WorkBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    9. Boundary Value Problems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-10/Chapter-10-WorkBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    10. Elliptic PDEs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-11/Chapter-11-WorkBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    11. Parabolic PDEs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-12/Chapter-12-WorkBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    12. Hyperbolic PDEs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-13/Chapter-13-WorkBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    13. Systems of Linear Equations
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-14/Chapter-14-WorkBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    14. Eigenvalue Problems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-15/Chapter-15-WorkBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    15. Fourier Analysis & The FFT
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter-16-WorkBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    16. Data-Driven Analysis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-17/Chapter-17-WorkBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    17. Randomness in Physics
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    CodeBooks
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    CodeBooks
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-1/Chapter-1-CodeBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1. Digital Lab Notebook
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-2/Chapter-2-CodeBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2. Computational Numbers
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-3/Chapter-3-CodeBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    3. Root Finding
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-4/Chapter-4-CodeBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    4. Interpolation & Fitting
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-5/Chapter-5-CodeBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    5. Numerical Differentiation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-6/Chapter-6-CodeBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    6. Numerical Integration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-7/Chapter-7-CodeBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    7. Initial Value Problems I
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-8/Chapter-8-CodeBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    8. Initial Value Problems II
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-9/Chapter-9-CodeBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    9. Boundary Value Problems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-10/Chapter-10-CodeBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    10. Elliptic PDEs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-11/Chapter-11-CodeBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    11. Parabolic PDEs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-12/Chapter-12-CodeBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    12. Hyperbolic PDEs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-13/Chapter-13-CodeBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    13. Systems of Linear Equations
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-14/Chapter-14-CodeBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    14. Eigenvalue Problems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-15/Chapter-15-CodeBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    15. Fourier Analysis & The FFT
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter-16-CodeBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    16. Data-Driven Analysis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-17/Chapter-17-CodeBook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    17. Randomness in Physics
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/bigbookofcomputing/foundation/edit/master/docs/chapters/chapter-16/Chapter-16-Quizes.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/bigbookofcomputing/foundation/raw/master/docs/chapters/chapter-16/Chapter-16-Quizes.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


  <h1>Chapter 16 Quizes</h1>

<div class="admonition note">
<p class="admonition-title">Quiz</p>
<hr />
<details class="question">
<summary>1. What is the primary challenge that Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) are designed to address in the context of modern computational physics?</summary>
<ul>
<li>a) Solving non-linear ordinary differential equations.</li>
<li>b) The 'Data Deluge' problem: finding dominant, underlying patterns in massive, high-dimensional data matrices.</li>
<li>c) Calculating the frequency components of a time-domain signal.</li>
<li>d) Ensuring the numerical stability of PDE solvers.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>b) The 'Data Deluge' problem: finding dominant, underlying patterns in massive, high-dimensional data matrices.</strong></li>
<li><strong>Explanation:</strong> As simulations produce vast amounts of data (e.g., molecular dynamics trajectories), PCA and SVD are essential for reducing dimensionality and extracting meaningful physical insights from the chaos.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>2. The Singular Value Decomposition (SVD) factorizes any matrix <span class="arithmatex">\(\mathbf{X}\)</span> into the product <span class="arithmatex">\(\mathbf{U} \mathbf{\Sigma} \mathbf{V}^T\)</span>. What do the diagonal entries of the <span class="arithmatex">\(\mathbf{\Sigma}\)</span> matrix represent?</summary>
<ul>
<li>a) The principal components of the data.</li>
<li>b) The mean of each column in <span class="arithmatex">\(\mathbf{X}\)</span>.</li>
<li>c) The singular values (<span class="arithmatex">\(\sigma_i\)</span>), which quantify the 'importance' or magnitude of each corresponding mode.</li>
<li>d) The eigenvectors of the data matrix <span class="arithmatex">\(\mathbf{X}\)</span>.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>c) The singular values (<span class="arithmatex">\(\sigma_i\)</span>), which quantify the 'importance' or magnitude of each corresponding mode.</strong></li>
<li><strong>Explanation:</strong> The singular values are sorted in descending order and represent the amount of variance or energy captured by each singular vector, making them crucial for ranking and truncation.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>3. How does truncated SVD achieve data compression and noise filtering?</summary>
<ul>
<li>a) By increasing the precision of the floating-point numbers in the matrix.</li>
<li>b) By keeping only the top <span class="arithmatex">\(K\)</span> largest singular values and their corresponding vectors, discarding the smaller values which often represent noise.</li>
<li>c) By applying a Fourier transform to the data.</li>
<li>d) By centering the data around its mean.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>b) By keeping only the top <span class="arithmatex">\(K\)</span> largest singular values and their corresponding vectors, discarding the smaller values which often represent noise.</strong></li>
<li><strong>Explanation:</strong> SVD provides a low-rank approximation of the matrix by retaining the most significant components, effectively compressing the data and filtering out high-frequency noise.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>4. What is the primary goal of Principal Component Analysis (PCA)?</summary>
<ul>
<li>a) To find the inverse of the data matrix.</li>
<li>b) To transform the data into a new, orthogonal basis where the axes (Principal Components) are aligned with the directions of greatest variance.</li>
<li>c) To calculate the determinant of the covariance matrix.</li>
<li>d) To solve a system of linear equations.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>b) To transform the data into a new, orthogonal basis where the axes (Principal Components) are aligned with the directions of greatest variance.</strong></li>
<li><strong>Explanation:</strong> PCA finds the 'natural' axes of a data cloud, allowing for dimensionality reduction and easier interpretation of the system's behavior.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>5. Mathematically, PCA is achieved by solving the eigenvalue problem for which specific matrix derived from the data <span class="arithmatex">\(\mathbf{X}\)</span>?</summary>
<ul>
<li>a) The original data matrix <span class="arithmatex">\(\mathbf{X}\)</span> itself.</li>
<li>b) The inverse of the data matrix, <span class="arithmatex">\(\mathbf{X}^{-1}\)</span>.</li>
<li>c) The Covariance Matrix, <span class="arithmatex">\(\mathbf{C} \propto \mathbf{X}^T \mathbf{X}\)</span>.</li>
<li>d) The identity matrix.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>c) The Covariance Matrix, <span class="arithmatex">\(\mathbf{C} \propto \mathbf{X}^T \mathbf{X}\)</span>.</strong></li>
<li><strong>Explanation:</strong> The eigenvectors of the symmetric covariance matrix are the principal components, and the eigenvalues represent the variance along those components.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>6. In the context of PCA, what do the eigenvectors (<span class="arithmatex">\(\mathbf{v}_i\)</span>) and eigenvalues (<span class="arithmatex">\(\lambda_i\)</span>) of the covariance matrix represent?</summary>
<ul>
<li>a) Eigenvectors are the variance; eigenvalues are the principal components.</li>
<li>b) Eigenvectors are the principal components (the new axes); eigenvalues are the variance along those axes.</li>
<li>c) Eigenvectors are the singular values; eigenvalues are the left singular vectors.</li>
<li>d) Both represent the amount of noise in the data.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>b) Eigenvectors are the principal components (the new axes); eigenvalues are the variance along those axes.</strong></li>
<li><strong>Explanation:</strong> This is the fundamental mapping between the linear algebra result and the physical interpretation in PCA.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>7. What is the crucial first step that must be performed on the data matrix <span class="arithmatex">\(\mathbf{X}\)</span> before calculating the covariance matrix in PCA?</summary>
<ul>
<li>a) Normalize each column to have a unit norm.</li>
<li>b) Center the data by subtracting the mean of each column.</li>
<li>c) Transpose the matrix.</li>
<li>d) Compute its SVD.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>b) Center the data by subtracting the mean of each column.</strong></li>
<li><strong>Explanation:</strong> PCA is about variance around the mean, so the data must first be centered to have a mean of zero.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>8. What is the relationship between the SVD of a data matrix <span class="arithmatex">\(\mathbf{X}\)</span> and the PCA of that same data?</summary>
<ul>
<li>a) There is no relationship between them.</li>
<li>b) The left singular vectors (<span class="arithmatex">\(\mathbf{U}\)</span>) of <span class="arithmatex">\(\mathbf{X}\)</span> are the principal components.</li>
<li>c) The right singular vectors (<span class="arithmatex">\(\mathbf{V}\)</span>) of <span class="arithmatex">\(\mathbf{X}\)</span> are the principal components (the eigenvectors of <span class="arithmatex">\(\mathbf{X}^T \mathbf{X}\)</span>).</li>
<li>d) The singular values are the principal components.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>c) The right singular vectors (<span class="arithmatex">\(\mathbf{V}\)</span>) of <span class="arithmatex">\(\mathbf{X}\)</span> are the principal components (the eigenvectors of <span class="arithmatex">\(\mathbf{X}^T \mathbf{X}\)</span>).</strong></li>
<li><strong>Explanation:</strong> Computing PCA via SVD is often more numerically stable than forming and solving the eigenvalue problem for the covariance matrix directly.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>9. In analyzing a molecular dynamics trajectory with PCA, what do the first few principal components with the largest eigenvalues typically represent?</summary>
<ul>
<li>a) Random, uncorrelated thermal noise.</li>
<li>b) The initial positions of the atoms.</li>
<li>c) Coherent, collective physical motions of the system (e.g., rotation, vibration, folding).</li>
<li>d) Errors in the simulation's force field.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>c) Coherent, collective physical motions of the system (e.g., rotation, vibration, folding).</strong></li>
<li><strong>Explanation:</strong> PCA excels at separating the low-dimensional, large-amplitude collective motions from the high-dimensional, small-amplitude thermal noise.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>10. When using SVD for image compression, a 500x500 pixel image has 500 singular values. If you reconstruct the image using only the top K=10 singular values, what is the expected result?</summary>
<ul>
<li>a) A perfectly clear image, identical to the original.</li>
<li>b) A heavily distorted image with no recognizable features.</li>
<li>c) A blurrier but recognizable version of the original image.</li>
<li>d) An inverted-color version of the image.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>c) A blurrier but recognizable version of the original image.</strong></li>
<li><strong>Explanation:</strong> The top 10 singular values capture the most dominant, low-rank features of the image, preserving its main structure but losing fine details.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>11. In the Python codebook, which <code>scipy.linalg</code> function is used to solve the symmetric eigenvalue problem for the covariance matrix in PCA?</summary>
<ul>
<li>a) <code>svd()</code></li>
<li>b) <code>inv()</code></li>
<li>c) <code>eigh()</code></li>
<li>d) <code>solve()</code></li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>c) <code>eigh()</code></strong></li>
<li><strong>Explanation:</strong> <code>eigh</code> is specifically designed for symmetric (or Hermitian) matrices like the covariance matrix, making it faster and more numerically stable than the general <code>eig</code> solver.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>12. After performing PCA, how is the 'explained variance ratio' for each principal component calculated?</summary>
<ul>
<li>a) By dividing each eigenvalue by the number of dimensions.</li>
<li>b) By dividing each eigenvalue by the total sum of all eigenvalues.</li>
<li>c) By taking the square root of each eigenvalue.</li>
<li>d) It is equal to the singular value.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>b) By dividing each eigenvalue by the total sum of all eigenvalues.</strong></li>
<li><strong>Explanation:</strong> This ratio shows the percentage of the total data variance that is captured by each individual principal component.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>13. To project the high-dimensional centered data <code>X_centered</code> onto a 2D subspace defined by the first two principal components (PC1, PC2), what matrix operation is performed?</summary>
<ul>
<li>a) <code>X_reduced = X_centered + [PC1, PC2]</code></li>
<li>b) <code>X_reduced = X_centered @ [PC1, PC2]</code> (Matrix multiplication)</li>
<li>c) <code>X_reduced = X_centered * [PC1, PC2]</code> (Element-wise multiplication)</li>
<li>d) <code>X_reduced = [PC1, PC2] @ X_centered</code></li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>b) <code>X_reduced = X_centered @ [PC1, PC2]</code> (Matrix multiplication)</strong></li>
<li><strong>Explanation:</strong> Projecting the data onto the new basis is done by matrix-multiplying the centered data by the matrix whose columns are the desired principal components.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>14. In the SVD code example for image filtering, the filtered matrix is reconstructed using <code>X_filtered = U_k @ s_k @ Vt_k</code>. What does <code>s_k</code> represent?</summary>
<ul>
<li>a) The full array of singular values.</li>
<li>b) A diagonal matrix containing only the top <code>K</code> truncated singular values.</li>
<li>c) The first <code>K</code> columns of the <code>U</code> matrix.</li>
<li>d) A single scalar value.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>b) A diagonal matrix containing only the top <code>K</code> truncated singular values.</strong></li>
<li><strong>Explanation:</strong> The <code>s</code> output of <code>svd</code> is a 1D array, which must be converted back into a diagonal matrix <code>s_k</code> for the reconstruction matrix multiplication.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>15. If the PCA of a 10-dimensional dataset reveals that 99% of the variance is captured by the first 2 principal components, what does this imply about the data?</summary>
<ul>
<li>a) The data is essentially random noise.</li>
<li>b) The data has a true, intrinsic dimensionality of 2, despite being embedded in a 10D space.</li>
<li>c) The PCA calculation has failed.</li>
<li>d) All 10 dimensions are equally important.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>b) The data has a true, intrinsic dimensionality of 2, despite being embedded in a 10D space.</strong></li>
<li><strong>Explanation:</strong> This is a classic sign that the data lies on or near a low-dimensional manifold (like a plane or curve) within the higher-dimensional space.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>16. The covariance matrix <code>C</code> is always:</summary>
<ul>
<li>a) Diagonal</li>
<li>b) Invertible</li>
<li>c) Symmetric</li>
<li>d) An orthogonal matrix</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>c) Symmetric</strong></li>
<li><strong>Explanation:</strong> The covariance of variable A with B is the same as B with A, making the covariance matrix symmetric. This property guarantees real eigenvalues and orthogonal eigenvectors.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>17. In the SVD formula <span class="arithmatex">\(\mathbf{X} = \mathbf{U} \mathbf{\Sigma} \mathbf{V}^T\)</span>, what are the properties of the matrices <span class="arithmatex">\(\mathbf{U}\)</span> and <span class="arithmatex">\(\mathbf{V}\)</span>?</summary>
<ul>
<li>a) They are both diagonal.</li>
<li>b) They are both symmetric.</li>
<li>c) They are both orthogonal matrices.</li>
<li>d) They are both singular.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>c) They are both orthogonal matrices.</strong></li>
<li><strong>Explanation:</strong> Orthogonality means their columns (and rows) form orthonormal bases, which is key to their role as basis vectors for the row and column spaces of <span class="arithmatex">\(\mathbf{X}\)</span>.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>18. When analyzing the sorted eigenvalues from a PCA of a physical system, a sharp 'cliff' in the plot (a few large values followed by a long tail of tiny values) indicates what?</summary>
<ul>
<li>a) A clear separation between coherent physical motion (large eigenvalues) and random noise (small eigenvalues).</li>
<li>b) A failure in the eigenvalue solver.</li>
<li>c) That the system is purely chaotic with no underlying structure.</li>
<li>d) That the data was not centered correctly.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>a) A clear separation between coherent physical motion (large eigenvalues) and random noise (small eigenvalues).</strong></li>
<li><strong>Explanation:</strong> This 'spectral gap' is the signature of a system with a low-dimensional set of important dynamics.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>19. Why is PCA considered a 'data-driven' analysis method?</summary>
<ul>
<li>a) Because it requires a physical model of the system to work.</li>
<li>b) Because the new basis vectors (the PCs) are determined entirely by the structure and correlations within the data itself, not by a predefined basis like Fourier analysis.</li>
<li>c) Because it only works on data that has been manually cleaned and labeled.</li>
<li>d) Because it was invented by data scientists.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>b) Because the new basis vectors (the PCs) are determined entirely by the structure and correlations within the data itself, not by a predefined basis like Fourier analysis.</strong></li>
<li><strong>Explanation:</strong> Unlike FFT which uses a fixed sinusoidal basis, PCA finds the optimal basis for a given dataset.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>20. In the Python code <code>C = np.cov(X_centered, rowvar=False)</code>, what is the purpose of the <code>rowvar=False</code> argument?</summary>
<ul>
<li>a) It tells the function that the matrix is not square.</li>
<li>b) It specifies that each column represents a variable and each row is an observation.</li>
<li>c) It prevents the calculation of the variance.</li>
<li>d) It tells the function that each row represents a variable and each column is an observation.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>b) It specifies that each column represents a variable and each row is an observation.</strong></li>
<li><strong>Explanation:</strong> This is the standard data layout for many scientific and statistical applications, and <code>np.cov</code> needs to know which dimension to calculate the covariance across.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>21. The SVD is described as the 'master factorization' in linear algebra because:</summary>
<ul>
<li>a) It is the fastest algorithm to compute.</li>
<li>b) It applies to any arbitrary matrix, regardless of whether it is square, symmetric, or invertible.</li>
<li>c) It was the first matrix factorization to be discovered.</li>
<li>d) It is only used for data compression.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>b) It applies to any arbitrary matrix, regardless of whether it is square, symmetric, or invertible.</strong></li>
<li><strong>Explanation:</strong> Its generality and the complete picture it provides of a matrix's structure make it a fundamental tool.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>22. If PC1 explains 84% of the variance and PC2 explains 15%, what is the cumulative variance explained by the first two components?</summary>
<ul>
<li>a) 69%</li>
<li>b) 84%</li>
<li>c) 99%</li>
<li>d) 100%</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>c) 99%</strong></li>
<li><strong>Explanation:</strong> The cumulative variance is the sum of the individual variances (84% + 15% = 99%).</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>23. The three pillars of computation developed in Volume I are Deterministic Solvers, Data-Driven Analysis, and what final ingredient, which is the subject of Chapter 17?</summary>
<ul>
<li>a) Quantum Computing</li>
<li>b) Artificial Intelligence</li>
<li>c) Randomness (for Monte Carlo methods)</li>
<li>d) GPU Programming</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>c) Randomness (for Monte Carlo methods)</strong></li>
<li><strong>Explanation:</strong> The book builds a toolkit for deterministic systems (solvers), data analysis (FFT/PCA), and finally, probabilistic systems (Monte Carlo).</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>24. When visualizing the singular values of a noisy image matrix on a log-plot, the 'knee' or 'elbow' in the plot often suggests a good rank <code>K</code> for truncation. Why?</summary>
<ul>
<li>a) It marks the point where the singular values become zero.</li>
<li>b) It indicates the transition point where the singular values stop representing the main signal and start representing noise.</li>
<li>c) It is always located at K=10.</li>
<li>d) It corresponds to the Nyquist frequency of the image.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>b) It indicates the transition point where the singular values stop representing the main signal and start representing noise.</strong></li>
<li><strong>Explanation:</strong> The initial steep drop represents the important structural components, while the long, flat tail represents the noise floor. The 'elbow' is the optimal point to separate them.</li>
</ul>
</details>
</details>
<hr />
<details class="question">
<summary>25. After sorting the eigenvalues and eigenvectors from <code>eigh</code>, why is it necessary to reorder the eigenvectors according to the sorted eigenvalue indices (<code>eigenvectors[:, idx]</code>)?</summary>
<ul>
<li>a) The <code>eigh</code> function does not guarantee that the eigenvalues and their corresponding eigenvectors are returned in the same order.</li>
<li>b) The <code>eigh</code> function returns eigenvalues in ascending order, but PCA requires them in descending order, so the eigenvectors must be reordered to match.</li>
<li>c) The eigenvectors are randomly shuffled by default.</li>
<li>d) It is not necessary; the order is always correct.</li>
</ul>
<details class="info">
<summary>See Answer</summary>
<ul>
<li><strong>b) The <code>eigh</code> function returns eigenvalues in ascending order, but PCA requires them in descending order, so the eigenvectors must be reordered to match.</strong></li>
<li><strong>Explanation:</strong> To ensure that the first principal component (PC1) corresponds to the largest eigenvalue (variance), both arrays must be sorted in the same descending order.</li>
</ul>
</details>
</details>
<hr />
</div>









  




                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://bigbookofcomputing.github.io" target="_blank" rel="noopener" title="bigbookofcomputing.github.io" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://x.com/bigbookofcomputing" target="_blank" rel="noopener" title="x.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M459.4 151.7c.3 4.5.3 9.1.3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53C87.4 130.8 165 172.4 252.1 176.9c-1.6-7.8-2.6-15.9-2.6-24C249.5 95.1 296.3 48 354.4 48c30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.facebook.com/bigbookofcomputing" target="_blank" rel="noopener" title="www.facebook.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M512 256C512 114.6 397.4 0 256 0S0 114.6 0 256c0 120 82.7 220.8 194.2 248.5V334.2h-52.8V256h52.8v-33.7c0-87.1 39.4-127.5 125-127.5 16.2 0 44.2 3.2 55.7 6.4V172c-6-.6-16.5-1-29.6-1-42 0-58.2 15.9-58.2 57.2V256h83.6l-14.4 78.2H287v175.9C413.8 494.8 512 386.9 512 256"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/bigbookofcomputing" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.youtube.com/@big-book-of-computing" target="_blank" rel="noopener" title="www.youtube.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M549.7 124.1c-6.2-23.7-24.8-42.3-48.3-48.6C458.9 64 288.1 64 288.1 64S117.3 64 74.7 75.5c-23.5 6.3-42 24.9-48.3 48.6C15 167 15 256.4 15 256.4s0 89.4 11.4 132.3c6.3 23.6 24.8 41.5 48.3 47.8C117.3 448 288.1 448 288.1 448s170.8 0 213.4-11.5c23.5-6.3 42-24.2 48.3-47.8 11.4-42.9 11.4-132.3 11.4-132.3s0-89.4-11.4-132.3zM232.2 337.6V175.2l142.7 81.2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
      <div class="md-consent" data-md-component="consent" id="__consent" hidden>
        <div class="md-consent__overlay"></div>
        <aside class="md-consent__inner">
          <form class="md-consent__form md-grid md-typeset" name="consent">
            


  


<h4>Cookie consent</h4>
<p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p>
<input class="md-toggle" type="checkbox" id="__settings" >
<div class="md-consent__settings">
  <ul class="task-list">
    
    
      
        
  
  
    
    
  
  <li class="task-list-item">
    <label class="task-list-control">
      <input type="checkbox" name="analytics" checked>
      <span class="task-list-indicator"></span>
      Google Analytics
    </label>
  </li>

      
    
    
      
        
  
  
    
    
  
  <li class="task-list-item">
    <label class="task-list-control">
      <input type="checkbox" name="github" checked>
      <span class="task-list-indicator"></span>
      GitHub
    </label>
  </li>

      
    
    
  </ul>
</div>
<div class="md-consent__controls">
  
    
      <button class="md-button md-button--primary">Accept</button>
    
    
    
  
    
    
    
      <label class="md-button" for="__settings">Manage settings</label>
    
  
</div>
          </form>
        </aside>
      </div>
      <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout((function(){document.querySelector("[data-md-component=consent]").hidden=!1}),250);var form=document.forms.consent;for(var action of["submit","reset"])form.addEventListener(action,(function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map((function(e){return[e,!0]})))),location.hash="",location.reload()}))</script>
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.tooltips", "navigation.footer", "navigation.indexes", "navigation.sections", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../../static/mathjax-config.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>